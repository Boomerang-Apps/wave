# V11.2 Architecture Fix Plan

## Executive Summary

The V11.2 worktree architecture failed because it isolated agents without providing shared access to:
1. Story files
2. Signal files for coordination
3. Gate progression enforcement

This document outlines the fixes to make V11.2 work while maintaining worktree isolation benefits.

---

## Root Cause Analysis

### What V10.0.7 Had (Working)

```yaml
# All agents shared these mounts:
volumes:
  - ./stories:/workspace/stories:ro           # ALL agents see ALL stories
  - ./.claude:/workspace/.claude:rw           # ALL agents share signal files
  - ./CLAUDE.md:/workspace/CLAUDE.md:ro       # Shared safety protocol
```

### What V11.2 Had (Broken)

```yaml
# Each agent only saw its worktree:
volumes:
  - ./worktrees/fe-dev:/app                   # Isolated - no stories!
  - ./stories/wave5:/stories:ro               # Wrong path - agents look in /app/stories/
  - ./.claude:/signals                        # Wrong path - agents look in /app/.claude/
```

---

## The Fix: Shared + Isolated Hybrid

### Principle
- **Worktrees stay isolated** for git operations (each agent commits to its branch)
- **Stories are shared read-only** (all agents can read any story)
- **Signals are shared read-write** (all agents can coordinate via signals)

### Volume Mount Strategy

```yaml
volumes:
  # 1. Agent's worktree for code changes
  - ./worktrees/fe-dev:/app:rw

  # 2. SHARED stories (read-only) - mounted inside worktree path
  - ./stories:/app/stories:ro

  # 3. SHARED signals (read-write) - for coordination
  - ./.claude:/app/.claude:rw

  # 4. Shared protocol documents
  - ./CLAUDE.md:/app/CLAUDE.md:ro
```

### Path Resolution

| What Agent Looks For | Mount Source | Container Path |
|---------------------|--------------|----------------|
| Stories | `./stories/` | `/app/stories/wave5/*.json` |
| Signals | `./.claude/` | `/app/.claude/signal-*.json` |
| Code to modify | `./worktrees/fe-dev/` | `/app/src/...` |
| Safety protocol | `./CLAUDE.md` | `/app/CLAUDE.md` |

---

## Pre-Flight Validation Checklist

### Phase 1: Infrastructure (must pass before anything)

- [ ] `.env` file exists and has required variables
- [ ] Supabase DB connection successful
- [ ] Supabase Storage bucket 'photos' exists and is PUBLIC
- [ ] Slack webhook responds with 200
- [ ] Docker daemon running
- [ ] Docker image `maf-claude-agent:latest` exists
- [ ] GitHub repo accessible

### Phase 2: Wave Configuration (must pass before wave launch)

- [ ] `stories/wave{N}/` directory exists
- [ ] Story JSON files are valid and have required fields
- [ ] Docker-compose has `wave{N}-fe-dev`, `wave{N}-be-dev`, `wave{N}-qa` services
- [ ] Volume mounts in docker-compose resolve to existing paths
- [ ] Worktrees exist: `fe-dev`, `be-dev`, `qa`, `dev-fix`
- [ ] Worktrees are clean (no uncommitted changes)
- [ ] No stale signals from previous runs

### Phase 3: Path Resolution (new - critical)

- [ ] Stories will be accessible at `/app/stories/wave{N}/`
- [ ] Signals will be writable at `/app/.claude/`
- [ ] CLAUDE.md will be readable at `/app/CLAUDE.md`
- [ ] Agent can write to `/app/src/` (worktree is writable)

### Phase 4: Dry-Run Test (new - recommended)

- [ ] Start container with `--entrypoint /bin/sh`
- [ ] Verify `ls /app/stories/wave{N}/` shows story files
- [ ] Verify `touch /app/.claude/test-signal.json` works
- [ ] Verify `cat /app/CLAUDE.md` shows content
- [ ] Clean up test files

---

## Implementation Steps

### Step 1: Fix docker-compose-v11.2.yml

For EVERY wave service, update volumes to:

```yaml
wave{N}-fe-dev:
  volumes:
    - ./worktrees/fe-dev:/app:rw
    - ./stories:/app/stories:ro
    - ./.claude:/app/.claude:rw
    - ./CLAUDE.md:/app/CLAUDE.md:ro
```

### Step 2: Create comprehensive pre-flight-v2.sh

New validator that checks:
1. All Phase 1-4 items above
2. Actually tests path resolution in containers
3. Reports EXACTLY what will fail before launch

### Step 3: Update merge-watcher for V11.2

Ensure merge-watcher:
1. Monitors `./.claude/` (shared signal directory)
2. Syncs worktrees BEFORE QA runs
3. Merges from worktree branches to main

### Step 4: Create launch-v2.sh

New launch script that:
1. Runs pre-flight-v2.sh (blocks if fails)
2. Shows human-readable summary
3. Requires explicit APPROVE
4. Creates start signal in shared `.claude/`
5. Sends Slack notification

---

## Signal File Convention

All signals go to shared `.claude/` directory:

```
.claude/
├── signal-wave5-start.json           # Launch approved
├── signal-wave5-gate3-fe-complete.json    # FE done
├── signal-wave5-gate3-be-complete.json    # BE done
├── signal-wave5-gate4-approved.json       # QA passed
├── signal-wave5-gate4-rejected.json       # QA failed (if applicable)
└── archive/                               # Old signals moved here
```

---

## Why This Fixes the Problem

1. **Stories accessible**: `/app/stories/` mounted from project root
2. **Signals shared**: All agents write to same `.claude/`
3. **Worktrees isolated**: Code changes stay in separate git branches
4. **Merge-watcher works**: Can monitor single `.claude/` directory
5. **QA can validate**: Has access to signals AND merged code

---

## Rollback Plan

If V11.2 fix doesn't work, revert to V10.0.7 style:
```bash
cp /Users/elizager/Downloads/Testing/test-v10.0.7-photo-gallery/docker-compose.yml ./docker-compose-v10.yml
docker compose -f docker-compose-v10.yml up
```

---

## Validation Criteria for "Fixed"

The architecture is fixed when:

1. `./scripts/pre-flight-v2.sh 5` passes with all green
2. Agents start and can read their stories
3. FE/BE agents create completion signals in shared `.claude/`
4. Merge-watcher detects signals and triggers worktree sync
5. QA agent validates merged code (not empty worktree)
6. Full wave completes with Slack notifications at each gate

---

*Document created: 2026-01-17*
*Author: CTO Architect Agent*
